<html>
  <head>
    <meta charset="utf-8" />
<meta name="description" content="" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Hadoop系列之hadoop生态圈 | Ahualy</title>
<link rel="shortcut icon" href=" https://ahualy.github.io//favicon.ico?v=1564665921026">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
<link rel="stylesheet" href=" https://ahualy.github.io//styles/main.css">

<script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
<script src="https://cdn.bootcss.com/moment.js/2.23.0/moment.min.js"></script>


  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href=" https://ahualy.github.io/">
  <img class="avatar" src=" https://ahualy.github.io//images/avatar.png?v=1564665921026" alt="">
  </a>
  <h1 class="site-title">
    Ahualy
  </h1>
  <p class="site-description">
    翎幺
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu">
          归档
        </a>
      
    
      
        <a href=" https://ahualy.github.io//post/hadoop-first/" class="menu">
          标签
        </a>
      
    
      
        <a href="/post/about-ahualy" class="menu">
          关于
        </a>
      
    
  </div>
  <div class="social-container">
    
      
        <a href="https://github.com/ahualy" target="_blank">
          <i class="fab fa-github"></i>
        </a>
      
    
      
    
      
    
      
    
      
    
  </div>
</div>

      
        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              Hadoop系列之hadoop生态圈
            </h2>
            <div class="post-info">
              <time class="post-time">
                · 2019-05-11 ·
              </time>
              
            </div>
            
            <div class="post-content">
              <p><a href="https://hadoop.apache.org/"><img src="https://ahualy.github.io//post-images/1557117804182.jpg" alt=""></a></p>
<h4 id="1-hadoop-生态概况">1. hadoop 生态概况</h4>
<p>Hadoop是一个由Apache基金会所开发的分布式系统基础架构。</p>
<p>用户可以在不了解分布式底层细节的情况下，开发分布式程序。充分利用集群的威力进行高速运算和存储。</p>
<p>具有可靠、高效、可伸缩的特点。</p>
<p>Hadoop的核心是YARN,HDFS和Mapreduce</p>
<p>下图是hadoop生态系统，集成spark生态圈。在未来一段时间内，hadoop将于spark共存，hadoop与spark</p>
<p>都能部署在yarn、mesos的资源管理系统之上</p>
<p><img src="https://ahualy.github.io//post-images/1557568672151.png" alt=""></p>
<p>下面将分别对以上各组件进行简要介绍，具体介绍参见后续系列博文。</p>
<h4 id="2-hdfshadoop分布式文件系统">2、HDFS（Hadoop分布式文件系统）</h4>
<p>源自于Google的GFS论文，发表于2003年10月，HDFS是GFS克隆版。</p>
<p>HDFS是Hadoop体系中数据存储管理的基础。它是一个高度容错的系统，能检测和应对硬件故障，用于在低成本的通用硬件上运行。</p>
<p>HDFS简化了文件的一致性模型，通过流式数据访问，提供高吞吐量应用程序数据访问功能，适合带有大型数据集的应用程序。</p>
<p>它提供了一次写入多次读取的机制，数据以块的形式，同时分布在集群不同物理机器上。</p>
<p>client：切分文件，访问HDFS，与namenode交互，获取文件位置信息，与DataNode交互，读取和写入数据。</p>
<p>namenode：master节点，在hadoop1.x中只有一个，管理HDFS的名称空间和数据块映射信息，配置副本策略，处理客户 端请求。</p>
<p>DataNode：slave节点，存储实际的数据，汇报存储信息给namenode。</p>
<p>secondary namenode：辅助namenode，分担其工作量：定期合并fsimage和fsedits，推送给namenode；紧急情况下
和辅助恢复namenode，但其并非namenode的热备。</p>
<h4 id="3-mapreduce分布式计算框架">3、Mapreduce（分布式计算框架）</h4>
<p>源自于google的MapReduce论文，发表于2004年12月，Hadoop MapReduce是google MapReduce 克隆版。</p>
<p>MapReduce是一种分布式计算模型，用以进行大数据量的计算。它屏蔽了分布式计算框架细节，将计算抽象成map和reduce两部分，</p>
<p>其中Map对数据集上的独立元素进行指定的操作，生成键-值对形式中间结果。Reduce则对中间结果中相同“键”的所有“值”进行规约，以得到最终结果。</p>
<p>MapReduce非常适合在大量计算机组成的分布式并行环境里进行数据处理。</p>
<p>jobtracker：master节点，只有一个，管理所有作业，任务/作业的监控，错误处理等，将任务分解成一系列任务，并分派给tasktracker。</p>
<p>tacktracker：slave节点，运行 map task和reducetask；并与jobtracker交互，汇报任务状态。</p>
<p>map task：解析每条数据记录，传递给用户编写的map（）并执行，将输出结果写入到本地磁盘（如果为map—only作
业，则直接写入HDFS）。</p>
<p>reduce task：从map 它深刻地执行结果中，远程读取输入数据，对数据进行排序，将数据分组传递给用户编写的reduce
函数执行。</p>
<h4 id="4-hbase分布式列存数据库">4. HBASE（分布式列存数据库）</h4>
<p>源自Google的Bigtable论文，发表于2006年11月，HBase是Google Bigtable克隆版</p>
<p>HBase是一个建立在HDFS之上，面向列的针对结构化数据的可伸缩、高可靠、高性能、分布式和面向列的动态模式数据库。</p>
<p>HBase采用了BigTable的数据模型：增强的稀疏排序映射表（Key/Value），其中，键由行关键字、列关键字和时间戳构成。</p>
<p>HBase提供了对大规模数据的随机、实时读写访问，同时，HBase中保存的数据可以使用MapReduce来处理，它将数据存储和并行计算完美地结合在一起。</p>
<h4 id="5-zookeeper分布式协作服务">5. Zookeeper（分布式协作服务）</h4>
<p>源自Google的Chubby论文，发表于2006年11月，Zookeeper是Chubby克隆版</p>
<p>解决分布式环境下的数据管理问题：统一命名，状态同步，集群管理，配置同步等。</p>
<p>Hadoop的许多组件依赖于Zookeeper，它运行在计算机集群上面，用于管理Hadoop操作。</p>
<h4 id="6-hive数据仓库">6. HIVE（数据仓库）</h4>
<p>由facebook开源，最初用于解决海量结构化的日志数据统计问题。</p>
<p>Hive定义了一种类似SQL的查询语言(HQL),将SQL转化为MapReduce任务在Hadoop上执行。通常用于离线分析。</p>
<p>HQL用于运行存储在Hadoop上的查询语句，Hive让不熟悉MapReduce开发人员也能编写数据查询语句，然后这些语句被翻译为Hadoop上面的MapReduce任务。</p>
<h4 id="7pigad-hoc脚本">7.Pig(ad-hoc脚本）</h4>
<p>由yahoo!开源，设计动机是提供一种基于MapReduce的ad-hoc(计算在query时发生)数据分析工具</p>
<p>Pig定义了一种数据流语言—Pig Latin，它是MapReduce编程的复杂性的抽象,Pig平台包括运行环境和用于分析Hadoop数据集的脚本语言(Pig Latin)。</p>
<p>其编译器将Pig Latin翻译成MapReduce程序序列将脚本转换为MapReduce任务在Hadoop上执行。通常用于进行离线分析。</p>
<h4 id="8sqoop数据etl同步工具">8.Sqoop(数据ETL/同步工具）</h4>
<p>Sqoop是SQL-to-Hadoop的缩写，主要用于传统数据库和Hadoop之前传输数据。数据的导入和导出本质上是Mapreduce程序，充分利用了MR的并行化和容错性。</p>
<p>Sqoop利用数据库技术描述数据架构，用于在关系数据库、数据仓库和Hadoop之间转移数据。</p>
<h4 id="9flume日志收集工具">9.Flume（日志收集工具）</h4>
<p>Cloudera开源的日志收集系统，具有分布式、高可靠、高容错、易于定制和扩展的特点。</p>
<p>它将数据从产生、传输、处理并最终写入目标的路径的过程抽象为数据流，在具体的数据流中，数据源支持在Flume中定制数据发送方，从而支持收集各种不同协议数据。</p>
<p>同时，Flume数据流提供对日志数据进行简单处理的能力，如过滤、格式转换等。此外，Flume还具有能够将日志写往各种数据目标（可定制）的能力。</p>
<p>总的来说，Flume是一个可扩展、适合复杂环境的海量日志收集系统。当然也可以用于收集其他类型数据</p>
<h4 id="10mahout数据挖掘算法库">10.Mahout（数据挖掘算法库）</h4>
<p>Mahout起源于2008年，最初是Apache Lucent的子项目，它在极短的时间内取得了长足的发展，现在是Apache的顶级项目。</p>
<p>Mahout的主要目标是创建一些可扩展的机器学习领域经典算法的实现，旨在帮助开发人员更加方便快捷地创建智能应用程序。</p>
<p>Mahout现在已经包含了聚类、分类、推荐引擎（协同过滤）和频繁集挖掘等广泛使用的数据挖掘方法。</p>
<p>除了算法，Mahout还包含数据的输入/输出工具、与其他存储系统（如数据库、MongoDB 或Cassandra）集成等数据挖掘支持架构。</p>
<h4 id="11-oozie工作流调度器">11. Oozie(工作流调度器）</h4>
<p>Oozie是一个可扩展的工作体系，集成于Hadoop的堆栈，用于协调多个MapReduce作业的执行。它能够管理一个复杂的系统，基于外部事件来执行，外部事件包括数据的定时和数据的出现。</p>
<p>Oozie工作流是放置在控制依赖DAG（有向无环图 Direct Acyclic Graph）中的一组动作（例如，Hadoop的Map/Reduce作业、Pig作业等），其中指定了动作执行的顺序。</p>
<p>Oozie使用hPDL（一种XML流程定义语言）来描述这个图。</p>
<h4 id="12-yarn分布式资源管理器">12. Yarn(分布式资源管理器）</h4>
<p>YARN是下一代MapReduce，即MRv2，是在第一代MapReduce基础上演变而来的，主要是为了解决原始Hadoop扩展性较差，不支持多计算框架而提出的。
Yarn是下一代 Hadoop 计算平台，yarn是一个通用的运行时框架，用户可以编写自己的计算框架，在该运行环境中运行。
用于自己编写的框架作为客户端的一个lib，在运用提交作业时打包即可。该框架为提供了以下几个组件：</p>
<ul>
<li>
<p>资源管理：包括应用程序管理和机器资源管理</p>
</li>
<li>
<p>资源双层调度</p>
</li>
<li>
<p>容错性：各个组件均有考虑容错性</p>
</li>
<li>
<p>扩展性：可扩展到上万个节点</p>
</li>
</ul>
<h4 id="13-mesos分布式资源管理器">13. Mesos（分布式资源管理器）</h4>
<p>Mesos诞生于UC Berkeley的一个研究项目，现已成为Apache项目，当前有一些公司使用Mesos管理集群资源，比如Twitter。</p>
<p>与yarn类似，Mesos是一个资源统一管理和调度的平台，同样支持比如MR、steaming等多种运算框架。</p>
<h4 id="14-tachyon分布式内存文件系统">14. Tachyon（分布式内存文件系统）</h4>
<p>Tachyon（/'tæki:ˌɒn/ 意为超光速粒子）是以内存为中心的分布式文件系统，拥有高性能和容错能力，</p>
<p>能够为集群框架（如Spark、MapReduce）提供可靠的内存级速度的文件共享服务。</p>
<p>Tachyon诞生于UC Berkeley的AMPLab。</p>
<h4 id="15-tezdag计算模型">15. Tez(DAG计算模型)</h4>
<p>Tez是Apache最新开源的支持DAG作业的计算框架，它直接源于MapReduce框架，核心思想是将Map和Reduce两个操作进一步拆分，</p>
<p>即Map被拆分成Input、Processor、Sort、Merge和Output， Reduce被拆分成Input、Shuffle、Sort、Merge、Processor和Output等，</p>
<p>这样，这些分解后的元操作可以任意灵活组合，产生新的操作，这些操作经过一些控制程序组装后，可形成一个大的DAG作业。</p>
<p>目前hive支持mr、tez计算模型，tez能完美二进制mr程序，提升运算性能。</p>
<h4 id="16-spark内存dag计算模型">16. Spark(内存DAG计算模型)</h4>
<p>Spark是一个Apache项目，它被标榜为“快如闪电的集群计算”。它拥有一个繁荣的开源社区，并且是目前最活跃的Apache项目。</p>
<p>最早Spark是UC Berkeley AMP lab所开源的类Hadoop MapReduce的通用的并行计算框架。</p>
<p>Spark提供了一个更快、更通用的数据处理平台。和Hadoop相比，Spark可以让你的程序在内存中运行时速度提升100倍，或者在磁盘上运行时速度提升10倍</p>
<h4 id="17-giraph图计算模型">17. Giraph(图计算模型)</h4>
<p>Apache Giraph是一个可伸缩的分布式迭代图处理系统， 基于Hadoop平台，灵感来自 BSP (bulk synchronous parallel) 和 Google 的 Pregel。</p>
<p>最早出自雅虎。雅虎在开发Giraph时采用了Google工程师2010年发表的论文《Pregel：大规模图表处理系统》中的原理。后来，雅虎将Giraph捐赠给Apache软件基金会。</p>
<p>目前所有人都可以下载Giraph，它已经成为Apache软件基金会的开源项目，并得到Facebook的支持，获得多方面的改进。</p>
<h4 id="18-graphx图计算模型">18. GraphX(图计算模型）</h4>
<p>Spark GraphX最先是伯克利AMPLAB的一个分布式图计算框架项目，目前整合在spark运行框架中，为其提供BSP大规模并行图计算能力。</p>
<h4 id="19-mlib机器学习库">19. MLib（机器学习库）</h4>
<p>Spark MLlib是一个机器学习库，它提供了各种各样的算法，这些算法用来在集群上针对分类、回归、聚类、协同过滤等。</p>
<h4 id="20-streaming流计算模型">20. Streaming（流计算模型）</h4>
<p>Spark Streaming支持对流数据的实时处理，以微批的方式对实时数据进行计算</p>
<h4 id="21-kafka分布式消息队列">21. Kafka（分布式消息队列）</h4>
<p>Kafka是Linkedin于2010年12月份开源的消息系统，它主要用于处理活跃的流式数据。</p>
<p>活跃的流式数据在web网站应用中非常常见，这些数据包括网站的pv、用户访问了什么内容，搜索了什么内容等。</p>
<p>这些数据通常以日志的形式记录下来，然后每隔一段时间进行一次统计处理。</p>
<h4 id="22-phoenixhbase-sql接口">22. Phoenix（hbase sql接口）</h4>
<p>Apache Phoenix 是HBase的SQL驱动，Phoenix 使得Hbase 支持通过JDBC的方式进行访问，并将你的SQL查询转换成Hbase的扫描和相应的动作。</p>
<h4 id="23-ranger安全管理工具">23. ranger(安全管理工具）</h4>
<p>Apache ranger是一个hadoop集群权限框架，提供操作、监控、管理复杂的数据权限，它提供一个集中的管理机制，管理基于yarn的hadoop生态圈的所有数据权限。</p>
<h4 id="24-knoxhadoop安全网关">24. knox（hadoop安全网关）</h4>
<p>Apache knox是一个访问hadoop集群的restapi网关，它为所有rest访问提供了一个简单的访问接口点，能完成3A认证（Authentication，Authorization，Auditing）和SSO（单点登录）等</p>
<h4 id="25-falcon数据生命周期管理工具">25. falcon（数据生命周期管理工具）</h4>
<p>Apache Falcon 是一个面向Hadoop的、新的数据处理和管理平台，设计用于数据移动、数据管道协调、生命周期管理和数据发现。它使终端用户可以快速地将他们的数据及其相关的处理和管理任务“上载（onboard）”到Hadoop集群。</p>
<h4 id="26ambari安装部署配置管理工具">26.Ambari（安装部署配置管理工具）</h4>
<p>Apache Ambari 的作用来说，就是创建、管理、监视 Hadoop 的集群，是为了让 Hadoop 以及相关的大数据软件更容易使用的一个web工具。</p>
<p><strong>声明</strong><br>
转载 https://www.cnblogs.com/gridmix/p/5102694.html</p>
<p><img src="https://ahualy.github.io//post-images/1557118287381.png" alt=""></p>

            </div>
          </article>
        </div>
    
        
          <div class="next-post">
            <div class="next">下一篇</div>
            <a href=" https://ahualy.github.io//post/hadoop-first">
              <h3 class="post-title">
                Hadoop系列之基本概念及开发环境
              </h3>
            </a>
          </div>  
        

        
          
            <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>

<div id="gitalk-container"></div>

<script>

  var gitalk = new Gitalk({
    clientID: '6e5bf68152a48928afe7',
    clientSecret: '9fc75f6b2af7f297c3de1ce161b8f025ead74ae7',
    repo: 'ahualy.github.io',
    owner: 'ahualy',
    admin: ['ahualy'],
    id: location.pathname,      // Ensure uniqueness and length less than 50
    distractionFreeMode: false  // Facebook-like distraction free mode
  })

  gitalk.render('gitalk-container')

</script>

          

          
        
    
        <div class="site-footer">
  Powered by 
</div>

<script>
  hljs.initHighlightingOnLoad()
</script>

      </div>
    </div>
  </body>
</html>
